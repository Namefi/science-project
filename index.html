<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>Browser inference demo</title>
    <style>
        video, canvas {
            display: block;
            margin-top: 10px;
        }
        button {
            margin-top: 10px;
        }
    </style>
</head>
<body>
    <h1>Edge Impulse Classifier</h1>
    <button id="switchCameraBtn">Switch Camera</button>
    <video id="webcam" autoplay playsinline width="320" height="240"></video>
    <canvas id="canvas" width="320" height="240" style="display: none;"></canvas>
    <pre id="output">Waiting for input...</pre>

    <script src="edge-impulse-standalone.js"></script>
    <script src="run-impulse.js"></script>
    <script>
        let currentStream;
        let currentDeviceIndex = 0;
        let videoDevices = [];

        async function getVideoDevices() {
            const devices = await navigator.mediaDevices.enumerateDevices();
            videoDevices = devices.filter(device => device.kind === 'videoinput');
        }

        async function setupCamera(deviceId = null) {
            const constraints = {
                video: deviceId ? { deviceId: { exact: deviceId }, width: 320, height: 240 } : { width: 320, height: 240 },
                audio: false
            };

            if (currentStream) {
                currentStream.getTracks().forEach(track => track.stop());
            }

            currentStream = await navigator.mediaDevices.getUserMedia(constraints);
            const video = document.getElementById('webcam');
            video.srcObject = currentStream;

            return new Promise(resolve => {
                video.onloadedmetadata = () => resolve(video);
            });
        }

        document.getElementById('switchCameraBtn').addEventListener('click', async () => {
            currentDeviceIndex = (currentDeviceIndex + 1) % videoDevices.length;
            const deviceId = videoDevices[currentDeviceIndex].deviceId;
            await setupCamera(deviceId);
        });

        (async () => {
            await getVideoDevices();
            const video = await setupCamera(videoDevices[0]?.deviceId);

            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext('2d');
            const output = document.getElementById("output");

            var classifier = new EdgeImpulseClassifier();
            await classifier.init();

            setInterval(async () => {
                const resizedCanvas = document.createElement('canvas');
                resizedCanvas.width = 320;
                resizedCanvas.height = 320;
                const resizedCtx = resizedCanvas.getContext('2d');
                resizedCtx.drawImage(video, 0, 0, resizedCanvas.width, resizedCanvas.height);

                const imageData = resizedCtx.getImageData(0, 0, resizedCanvas.width, resizedCanvas.height);
                const rawRgbData = [];
                for (let i = 0; i < imageData.data.length; i += 4) {
                    rawRgbData.push(imageData.data[i]);
                    rawRgbData.push(imageData.data[i + 1]);
                    rawRgbData.push(imageData.data[i + 2]);
                }

                try {
                    const result = await classifier.classify(rawRgbData);
                    let outputText = 'Classification results:\n';
                    result.results.forEach((labelResult) => {
                        outputText += `${labelResult.label}: ${Math.round(labelResult.value * 100)}%\n`;
                    });
                    output.textContent = outputText;
                } catch (error) {
                    console.error('Error during inference:', error);
                    output.textContent = "Error during inference. Check the console for details.";
                }
            }, 1000);
        })();
    </script>
</body>
</html>
